{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import pretrainedmodels\n",
    "import time\n",
    "import openpyxl as pyxl\n",
    "import os, glob\n",
    "import json\n",
    "import argparse\n",
    "from openpyxl.styles import Font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_GPU = False\n",
    "model_label_path = \"/media/Share/jingyun/Pytorch-training/files/snapshot/foodNonfood-res50-classes.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_class: 2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and use_GPU else \"cpu\")\n",
    "label_dict = []\n",
    "with open(model_label_path, \"rt\") as label_file:\n",
    "    label_dict = [line.strip() for line in label_file.readlines()]\n",
    "num_class = len(label_dict)\n",
    "print(\"num_class:\", num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet50\"\n",
    "model_path = \"/media/Share/jingyun/Pytorch-training/files/snapshot/BestWeight-foodNonfood-res50-02-08-2019_17-07-57.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading in weights\n"
     ]
    }
   ],
   "source": [
    "model_ft2 = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "num_ftrs = model_ft2.last_linear.in_features\n",
    "model_ft2.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "model_ft2.last_linear = torch.nn.Linear(num_ftrs, num_class)\n",
    "print(\"loading in weights\")\n",
    "model_ft2.load_state_dict(torch.load(model_path,map_location='cpu'))\n",
    "model_ft2.eval()\n",
    "sm = torch.nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "model_ft2 = model_ft2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing /media/Share/jingyun/data/test0813_by/0 folder_id: 0\n",
      "including 0 /media/Share/jingyun/data/test0813_by/0\n",
      "processing /media/Share/jingyun/data/test0813_by/1 folder_id: 1\n",
      "including 1 /media/Share/jingyun/data/test0813_by/1\n"
     ]
    }
   ],
   "source": [
    "def dataset_list_JJ(path_to_dataset, keep_folder_id = []):\n",
    "    ret_dict = {}\n",
    "    for outer_folder in os.scandir(path_to_dataset):\n",
    "        try:\n",
    "            folder_id = outer_folder.name\n",
    "        except Exception as e:\n",
    "            print(outer_folder.name, e)\n",
    "            folder_id = outer_folder.name\n",
    "        print(\"processing\",outer_folder.path,\"folder_id:\",folder_id)\n",
    "        try:\n",
    "            folder_id = int(folder_id)\n",
    "        except:\n",
    "            print(outer_folder.name,\"cannot be change to an int\")\n",
    "        if len(keep_folder_id) and not str(folder_id) in keep_folder_id:\n",
    "            print(\"skipping\",outer_folder.path,\"it is marked as to skip\")\n",
    "            continue\n",
    "        print(\"including\",outer_folder.name, outer_folder.path)\n",
    "        ret_dict[outer_folder.name] = []\n",
    "        for file in glob.iglob(outer_folder.path+'/**/*.jpg', recursive=True):\n",
    "            if not \"@eaDir\" in file:\n",
    "                ret_dict[outer_folder.name].append(file)\n",
    "        for file in glob.iglob(outer_folder.path+'/**/*.jpeg', recursive=True):\n",
    "            if not \"@eaDir\" in file:\n",
    "                ret_dict[outer_folder.name].append(file)\n",
    "        for file in glob.iglob(outer_folder.path+'/**/*.JPEG', recursive=True):\n",
    "            if not \"@eaDir\" in file:\n",
    "                ret_dict[outer_folder.name].append(file)\n",
    "        for file in glob.iglob(outer_folder.path+'/**/*.JPG', recursive=True):\n",
    "            if not \"@eaDir\" in file:\n",
    "                ret_dict[outer_folder.name].append(file)\n",
    "        for file in glob.iglob(outer_folder.path+'/**/*.png', recursive=True):\n",
    "            if not \"@eaDir\" in file:\n",
    "                ret_dict[outer_folder.name].append(file)\n",
    "    return ret_dict\n",
    "\n",
    "def pil_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(e, \"img_path:\", path)\n",
    "\n",
    "val_dict_img_list = dataset_list_JJ(\"/media/Share/jingyun/data/test0813_by\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating food: 0\n",
      "Complete food: 0 in: 7.0574564933776855\n",
      "Validating food: 1\n",
      "Complete food: 1 in: 5.375919580459595\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "food_results = {}\n",
    "for food_label, img_list in val_dict_img_list.items():\n",
    "    time_since = time.time()\n",
    "    try:\n",
    "        food_label = food_label.strip()\n",
    "        food_label_idx = label_dict.index(food_label)\n",
    "    except Exception as e:\n",
    "        print(\"Not found! Skipping this food entirely\",e)\n",
    "        food_label_idx = len(label_dict)\n",
    "        continue\n",
    "    print(\"Validating food:\", food_label)\n",
    "    food_results[food_label] = {\"top1\":0,\"top5\":0,\"top25\":0,\"foundIn\":[],\"recogResult\":{},\"img_tested\":[],\"total\":len(img_list)}\n",
    "    for img_path in img_list:\n",
    "        if \"@eaDir\" in img_path:\n",
    "            continue\n",
    "        input_tensor = val_transform(pil_loader(img_path)).unsqueeze(0)\n",
    "        input_t = torch.autograd.Variable(input_tensor, requires_grad = False)\n",
    "        input_t = input_t.to(device)\n",
    "        output_logits = model_ft2(input_t)\n",
    "        prob = sm(output_logits)\n",
    "        prob, cls_id = prob.topk(k=len(label_dict), dim=1)\n",
    "        cls_list = cls_id.squeeze(0).tolist()\n",
    "        prob_list = prob.squeeze(0).tolist()\n",
    "        foundIn =  cls_list.index(food_label_idx)\n",
    "        food_results[food_label][\"foundIn\"].append(foundIn)\n",
    "        food_results[food_label][\"img_tested\"].append(img_path)\n",
    "        if foundIn <= 24:\n",
    "            food_results[food_label][\"top25\"] += 1\n",
    "        if foundIn <= 4:\n",
    "            food_results[food_label][\"top5\"] += 1\n",
    "        if foundIn == 0:\n",
    "            food_results[food_label][\"top1\"] += 1\n",
    "        if not label_dict[cls_list[0]] in food_results[food_label][\"recogResult\"]:\n",
    "            food_results[food_label][\"recogResult\"][label_dict[cls_list[0]]] = 0\n",
    "        food_results[food_label][\"recogResult\"][label_dict[cls_list[0]]] += 1\n",
    "    print(\"Complete food: {} in:\".format(food_label), time.time() - time_since)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'top1': 17,\n",
       "  'top5': 17,\n",
       "  'top25': 17,\n",
       "  'foundIn': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'recogResult': {'0': 17},\n",
       "  'img_tested': ['/media/Share/jingyun/data/test0813_by/0/IMG_2316.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3336.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3350.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3492.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3532.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3539.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3541.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3606.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3615.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3729.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3740.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3758.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3778.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3804.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3810.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3821.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/0/IMG_3823.png'],\n",
       "  'total': 17},\n",
       " '1': {'top1': 14,\n",
       "  'top5': 14,\n",
       "  'top25': 14,\n",
       "  'foundIn': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "  'recogResult': {'1': 14},\n",
       "  'img_tested': ['/media/Share/jingyun/data/test0813_by/1/IMG_3525.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/1/IMG_3526.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/1/IMG_3527.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/1/IMG_3528.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/1/IMG_3646.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/1/IMG_3667.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/1/IMG_3699.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/1/IMG_3700.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/1/IMG_3701.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/1/IMG_3702.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/1/IMG_3703.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/1/IMG_3704.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/1/IMG_3725.png',\n",
       "   '/media/Share/jingyun/data/test0813_by/1/IMG_3726.png'],\n",
       "  'total': 14}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating food: 0\n",
      "Complete food: 0 in: 65.83282089233398\n",
      "Validating food: 1\n",
      "Complete food: 1 in: 49.121927976608276\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "food_results = []\n",
    "for food_label, img_list in val_dict_img_list.items():\n",
    "    time_since = time.time()\n",
    "    class_label_indices = []\n",
    "    try:\n",
    "        food_label = food_label.strip()\n",
    "        food_label_idx = label_dict.index(food_label)\n",
    "    except Exception as e:\n",
    "        print(\"Not found! Skipping this food entirely\",e)\n",
    "        food_label_idx = len(label_dict)\n",
    "        continue\n",
    "    print(\"Validating food:\", food_label)\n",
    "    \n",
    "    for img_path in img_list:\n",
    "        if \"@eaDir\" in img_path:\n",
    "            continue\n",
    "        input_tensor = val_transform(pil_loader(img_path)).unsqueeze(0)\n",
    "        input_t = torch.autograd.Variable(input_tensor, requires_grad = False)\n",
    "        input_t = input_t.to(device)\n",
    "        output_logits = model_ft2(input_t)\n",
    "        prob = sm(output_logits)\n",
    "        prob, cls_id = prob.topk(k=len(label_dict), dim=1)\n",
    "        cls_list = cls_id.squeeze(0).tolist()\n",
    "        prob_list = prob.squeeze(0).tolist()\n",
    "        foundIn = num_class\n",
    "        firstTen = []\n",
    "        for i in range(len(cls_list)):\n",
    "            firstTen.append({\"name\":label_dict[cls_list[i]], \"confidence\":prob_list[i]})\n",
    "        foundIn = cls_list.index(food_label_idx)\n",
    "        img_obj = Image.open(img_path)\n",
    "        img_obj = img_obj.convert(\"RGB\")\n",
    "        img_obj.save(img_path)\n",
    "        food_results.append({\"ipath\":img_path,\"GTs\": food_label, \"foundIn\": foundIn, \"first 10 results\":firstTen})\n",
    "    print(\"Complete food: {} in:\".format(food_label), time.time() - time_since)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zipfile.ZipFile filename='test0813_by.xlsx' mode='w'>\n",
      "archive: ['docProps/app.xml', 'docProps/core.xml', 'xl/theme/theme1.xml', 'xl/worksheets/sheet1.xml', 'xl/drawings/drawing1.xml', 'xl/drawings/_rels/drawing1.xml.rels', 'xl/worksheets/_rels/sheet1.xml.rels', 'xl/media/image1.png', 'xl/media/image2.png', 'xl/media/image3.png', 'xl/media/image4.png', 'xl/media/image5.png', 'xl/media/image6.png', 'xl/media/image7.png', 'xl/media/image8.png', 'xl/media/image9.png', 'xl/media/image10.png', 'xl/media/image11.png', 'xl/media/image12.png', 'xl/media/image13.png', 'xl/media/image14.png', 'xl/media/image15.png', 'xl/media/image16.png', 'xl/media/image17.png', 'xl/media/image18.png', 'xl/media/image19.png', 'xl/media/image20.png', 'xl/media/image21.png', 'xl/media/image22.png', 'xl/media/image23.png', 'xl/media/image24.png', 'xl/media/image25.png', 'xl/media/image26.png', 'xl/media/image27.png', 'xl/media/image28.png', 'xl/media/image29.png', 'xl/media/image30.png', 'xl/media/image31.png', 'xl/styles.xml', '_rels/.rels', 'xl/workbook.xml', 'xl/_rels/workbook.xml.rels']\n",
      "fn: docProps/app.xml ext: .xml\n",
      "fn: docProps/core.xml ext: .xml\n",
      "fn: xl/theme/theme1.xml ext: .xml\n",
      "fn: xl/worksheets/sheet1.xml ext: .xml\n",
      "fn: xl/drawings/drawing1.xml ext: .xml\n",
      "fn: xl/drawings/_rels/drawing1.xml.rels ext: .rels\n",
      "fn: xl/worksheets/_rels/sheet1.xml.rels ext: .rels\n",
      "fn: xl/media/image1.png ext: .png\n",
      "fn: xl/media/image2.png ext: .png\n",
      "fn: xl/media/image3.png ext: .png\n",
      "fn: xl/media/image4.png ext: .png\n",
      "fn: xl/media/image5.png ext: .png\n",
      "fn: xl/media/image6.png ext: .png\n",
      "fn: xl/media/image7.png ext: .png\n",
      "fn: xl/media/image8.png ext: .png\n",
      "fn: xl/media/image9.png ext: .png\n",
      "fn: xl/media/image10.png ext: .png\n",
      "fn: xl/media/image11.png ext: .png\n",
      "fn: xl/media/image12.png ext: .png\n",
      "fn: xl/media/image13.png ext: .png\n",
      "fn: xl/media/image14.png ext: .png\n",
      "fn: xl/media/image15.png ext: .png\n",
      "fn: xl/media/image16.png ext: .png\n",
      "fn: xl/media/image17.png ext: .png\n",
      "fn: xl/media/image18.png ext: .png\n",
      "fn: xl/media/image19.png ext: .png\n",
      "fn: xl/media/image20.png ext: .png\n",
      "fn: xl/media/image21.png ext: .png\n",
      "fn: xl/media/image22.png ext: .png\n",
      "fn: xl/media/image23.png ext: .png\n",
      "fn: xl/media/image24.png ext: .png\n",
      "fn: xl/media/image25.png ext: .png\n",
      "fn: xl/media/image26.png ext: .png\n",
      "fn: xl/media/image27.png ext: .png\n",
      "fn: xl/media/image28.png ext: .png\n",
      "fn: xl/media/image29.png ext: .png\n",
      "fn: xl/media/image30.png ext: .png\n",
      "fn: xl/media/image31.png ext: .png\n",
      "fn: xl/styles.xml ext: .xml\n",
      "fn: xl/workbook.xml ext: .xml\n",
      "fn: xl/_rels/workbook.xml.rels ext: .rels\n"
     ]
    }
   ],
   "source": [
    "import openpyxl as pyxl\n",
    "from openpyxl.drawing.image import Image as pyxlImg\n",
    "from openpyxl.utils import get_column_letter\n",
    "import os\n",
    "\n",
    "errAnaWorkbook = pyxl.Workbook()\n",
    "ws = errAnaWorkbook.active\n",
    "ws.title = 'Err Report-bothTrials'\n",
    "ws.cell(row=1,column=1,value=\"Filename\")\n",
    "ws.cell(row=1,column=2,value=\"Image\")\n",
    "ws.cell(row=1,column=3,value=\"Ground truth(s)\")\n",
    "ws.cell(row=1,column=4,value=\"Found in\")\n",
    "ws.cell(row=1,column=5,value=\"First 10 results\")\n",
    "resStartRow = 1\n",
    "ws.column_dimensions[chr(ord('A')+1)].width = 18\n",
    "\n",
    "for entry in food_results:\n",
    "    resStartCol = 5\n",
    "    resStartRow += 1\n",
    "    testImg = pyxlImg(entry[\"ipath\"])\n",
    "    testImg.width = 120\n",
    "    testImg.height = 120\n",
    "    testImg.anchor = '{}{}'.format(get_column_letter(2),resStartRow)\n",
    "    ws.add_image(testImg)\n",
    "    ws.row_dimensions[resStartRow].height = 95\n",
    "    ws.cell(row=resStartRow,column=1,value=\"{}\".format(os.path.basename(entry[\"ipath\"])))\n",
    "    ws.cell(row=resStartRow,column=3,value=\"{}\".format(entry[\"GTs\"]))\n",
    "   # ws.cell(row=resStartRow,column=4,value=\"=value({})\".format(entry[\"foundIn\"]+1))\n",
    "    for res in entry[\"first 10 results\"]:\n",
    "        ws.cell(row=resStartRow,column=resStartCol,value=\"{} ({:0.3f})\".format(res[\"name\"], res[\"confidence\"]))\n",
    "        resStartCol += 1\n",
    "resStartRow += 1\n",
    "ws.cell(row=resStartRow,column=3,value=\"Top-1\")\n",
    "#ws.cell(row=resStartRow,column=4,value=\"=COUNTIF($D$2:$D${0},1)/COUNTA($D$2:$D${0})\".format(resStartRow-1))\n",
    "resStartRow += 1\n",
    "errAnaWorkbook.save(\"test0813_by.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (pytorch1.0)",
   "language": "python",
   "name": "pyt10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
